import os
import streamlit as st
from dotenv import load_dotenv

# LangChain Imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from langchain.memory import ChatMessageHistory
from langchain_core.messages import HumanMessage, AIMessage

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# --- 1. THI·∫æT L·∫¨P C·∫§U H√åNH V√Ä MODEL (Kh·ªüi t·∫°o m·ªôt l·∫ßn) ---

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    st.error("GROQ_API_KEY environment variable not found.")
    st.stop()

# Session ID c·ªë ƒë·ªãnh cho v√≠ d·ª• ƒë∆°n gi·∫£n n√†y
SESSION_ID = "stream_session_001"

# --- 2. THI·∫æT L·∫¨P B·ªò NH·ªö V√Ä CHAIN ---

# Kh·ªüi t·∫°o session state cho l·ªãch s·ª≠ tr√≤ chuy·ªán (d·∫°ng dictionary)
if "chat_history_store" not in st.session_state:
    st.session_state.chat_history_store = {}

# Kh·ªüi t·∫°o session state cho hi·ªÉn th·ªã l·ªãch s·ª≠ tr√≤ chuy·ªán (d·∫°ng list)
if "messages" not in st.session_state:
    st.session_state.messages = []


def get_session_history(session_id: str) -> ChatMessageHistory:
    """T·∫°o ho·∫∑c tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng ChatMessageHistory t·ª´ Streamlit session state."""
    if session_id not in st.session_state.chat_history_store:
        st.session_state.chat_history_store[session_id] = ChatMessageHistory()
    return st.session_state.chat_history_store[session_id]


# ƒê·ªãnh nghƒ©a Prompt Template
prompt = ChatPromptTemplate.from_messages([
    ("system",
     "You are a helpful assistant. Keep your answers concise and professional. Use the chat history to maintain context."),
    MessagesPlaceholder(variable_name="history"),
    ("user", "Question: {question}")
])

# Kh·ªüi t·∫°o Model
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    groq_api_key=GROQ_API_KEY
)

# T·∫°o Core Chain
core_chain = prompt | llm

# T·∫°o History-Aware Chain
history_chain = RunnableWithMessageHistory(
    core_chain,
    get_session_history,
    input_messages_key="question",
    history_messages_key="history",
)


# --- 3. H√ÄM X·ª¨ L√ù CH√çNH ---

def generate_response(question, session_id):
    """G·ªçi chain c√≥ l·ªãch s·ª≠ tr√≤ chuy·ªán."""
    config = {"configurable": {"session_id": session_id}}

    # LangChain s·∫Ω t·ª± ƒë·ªông th√™m v√† l·∫•y l·ªãch s·ª≠
    answer = history_chain.invoke({"question": question}, config=config)

    return answer.content


# --- 4. GIAO DI·ªÜN STREAMLIT CH√çNH ---

st.set_page_config(page_title="Khung Chat 2 Ph√≠a", layout="wide")
st.title("üí¨ Chatbot with Groq")


# 1. Hi·ªÉn th·ªã l·ªãch s·ª≠ tr√≤ chuy·ªán ƒë√£ l∆∞u trong st.session_state.messages
for message in st.session_state.messages:
    # L·∫•y vai tr√≤ (user ho·∫∑c assistant) ƒë·ªÉ x√°c ƒë·ªãnh v·ªã tr√≠ chat
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 2. X·ª≠ l√Ω Input c·ªßa ng∆∞·ªùi d√πng
if prompt_input := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):

    # 2a. Th√™m tin nh·∫Øn c·ªßa User v√†o l·ªãch s·ª≠ hi·ªÉn th·ªã
    st.session_state.messages.append({"role": "user", "content": prompt_input})

    # 2b. Hi·ªÉn th·ªã tin nh·∫Øn User ·ªü khung b√™n ph·∫£i
    with st.chat_message("user"):
        st.markdown(prompt_input)

    # 2c. G·ªçi LLM v√† hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa AI
    with st.chat_message("assistant"):
        with st.spinner("AI ƒëang suy nghƒ©..."):
            try:
                # G·ªçi h√†m sinh ph·∫£n h·ªìi (h√†m n√†y c√≥ c·∫£ logic LangChain/Memory)
                response = generate_response(prompt_input, SESSION_ID)

                # In ph·∫£n h·ªìi c·ªßa AI ra m√†n h√¨nh
                st.markdown(response)

                # 2d. Th√™m tin nh·∫Øn c·ªßa AI v√†o l·ªãch s·ª≠ hi·ªÉn th·ªã
                st.session_state.messages.append({"role": "assistant", "content": response})

            except Exception as e:
                error_msg = f"ƒê√£ x·∫£y ra l·ªói: {e}. Vui l√≤ng ki·ªÉm tra API key."
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})